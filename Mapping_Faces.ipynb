{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibeToUnvHXq4",
    "outputId": "c064cf23-b37a-44cc-a6a6-d0c343c8e4c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.1+cu121 in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (3.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1+cu121) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1+cu121) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.4.1+cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4E5xRg1GB74",
    "outputId": "d2c43238-2d81-4de6-a1c6-824d136486fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio==2.2.2\n",
      "  Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting torch==2.2.2 (from torchaudio==2.2.2)\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchaudio==2.2.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchaudio==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchaudio==2.2.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchaudio==2.2.2) (3.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchaudio==2.2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchaudio==2.2.2) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.2->torchaudio==2.2.2)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchaudio==2.2.2) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->torchaudio==2.2.2) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->torchaudio==2.2.2) (1.3.0)\n",
      "Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchaudio\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.5.0.50\n",
      "    Uninstalling nvidia-cudnn-cu12-9.5.0.50:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.5.0.50\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1+cu121\n",
      "    Uninstalling torch-2.4.1+cu121:\n",
      "      Successfully uninstalled torch-2.4.1+cu121\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.4.1+cu121\n",
      "    Uninstalling torchaudio-2.4.1+cu121:\n",
      "      Successfully uninstalled torchaudio-2.4.1+cu121\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchaudio-2.2.2 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install torchaudio==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "mf6-gu8gB2wv",
    "outputId": "23572cf4-2823-446b-8758-0930ab037029"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from facenet_pytorch import MTCNN\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVPerspectiveCameras,\n",
    "    PointLights,\n",
    "    DirectionalLights,\n",
    "    Materials,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    SoftPhongShader,\n",
    "    TexturesVertex\n",
    ")\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance,\n",
    "    mesh_edge_loss,\n",
    "    mesh_laplacian_smoothing,\n",
    "    mesh_normal_consistency,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tf6mGk7FBxDt"
   },
   "outputs": [],
   "source": [
    "# 1. Implement a real 3D face reconstruction model\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 4, 2, 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4, 2, 1)\n",
    "        self.fc = nn.Linear(256 * 16 * 16, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_vertices):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_vertices * 3)  # 3D coordinates\n",
    "        self.fc3 = nn.Linear(1024, num_vertices * 3)  # RGB colors\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        vertices = self.fc2(x).view(-1, 3)\n",
    "        colors = torch.sigmoid(self.fc3(x)).view(-1, 3)\n",
    "        return vertices, colors\n",
    "\n",
    "class FaceReconstructionModel(nn.Module):\n",
    "    def __init__(self, num_vertices):\n",
    "        super(FaceReconstructionModel, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder(num_vertices)\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        vertices, colors = self.decoder(latent)\n",
    "        return vertices, colors\n",
    "\n",
    "# Face detection for preprocessing\n",
    "mtcnn = MTCNN(keep_all=True, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# Custom dataset\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect face\n",
    "        boxes, _ = mtcnn.detect(image)\n",
    "        if boxes is not None:\n",
    "            box = boxes[0]\n",
    "            face = image[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "        else:\n",
    "            face = image  # If no face detected, use the whole image\n",
    "\n",
    "        face = cv2.resize(face, (256, 256))\n",
    "\n",
    "        if self.transform:\n",
    "            face = self.transform(face)\n",
    "\n",
    "        return face\n",
    "\n",
    "# Data loading and preprocessing\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    dataset = FaceDataset(image_paths, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqdz3jDfB_-v"
   },
   "outputs": [],
   "source": [
    "# 2. Define face connectivity\n",
    "def create_face_mesh(vertices, colors, resolution=100):\n",
    "    u = np.linspace(0, 1, resolution)\n",
    "    v = np.linspace(0, 1, resolution)\n",
    "    u, v = np.meshgrid(u, v)\n",
    "    u = u.flatten()\n",
    "    v = v.flatten()\n",
    "\n",
    "    x = vertices[:, 0].reshape((resolution, resolution))\n",
    "    y = vertices[:, 1].reshape((resolution, resolution))\n",
    "    z = vertices[:, 2].reshape((resolution, resolution))\n",
    "\n",
    "    faces = []\n",
    "    for i in range(resolution-1):\n",
    "        for j in range(resolution-1):\n",
    "            faces.append([i*resolution+j, (i+1)*resolution+j, i*resolution+j+1])\n",
    "            faces.append([(i+1)*resolution+j, (i+1)*resolution+j+1, i*resolution+j+1])\n",
    "\n",
    "    return vertices, faces, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbtHPCBNCF0r"
   },
   "outputs": [],
   "source": [
    "# 3. Fine-tune rendering parameters\n",
    "class FaceRenderer:\n",
    "    def __init__(self, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        self.device = device\n",
    "\n",
    "    def setup_renderer(self, image_size=512):\n",
    "        R, T = look_at_view_transform(2.7, 0, 0)\n",
    "        cameras = FoVPerspectiveCameras(device=self.device, R=R, T=T)\n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=image_size,\n",
    "            blur_radius=0.0,\n",
    "            faces_per_pixel=1,\n",
    "        )\n",
    "        lights = PointLights(device=self.device, location=[[0.0, 0.0, -3.0]])\n",
    "        materials = Materials(\n",
    "            device=self.device,\n",
    "            specular_color=[[0.2, 0.2, 0.2]],\n",
    "            shininess=32\n",
    "        )\n",
    "        renderer = MeshRenderer(\n",
    "            rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
    "            shader=SoftPhongShader(device=self.device, cameras=cameras, lights=lights, materials=materials)\n",
    "        )\n",
    "        return renderer\n",
    "\n",
    "    def render_views(self, vertices, faces, colors, num_views=8):\n",
    "        renderer = self.setup_renderer()\n",
    "        vertices = vertices.to(self.device)\n",
    "        faces = torch.tensor(faces, dtype=torch.int64, device=self.device)\n",
    "        colors = colors.to(self.device)\n",
    "        textures = TexturesVertex(colors.unsqueeze(0))\n",
    "        mesh = Meshes(verts=[vertices], faces=[faces], textures=textures)\n",
    "\n",
    "        images = []\n",
    "        for i in range(num_views):\n",
    "            angle = i * (360 / num_views)\n",
    "            R, T = look_at_view_transform(2.7, 0, angle)\n",
    "            cameras = FoVPerspectiveCameras(device=self.device, R=R, T=T)\n",
    "            image = renderer(mesh, cameras=cameras)\n",
    "            images.append(image[0, ..., :3].cpu().numpy())\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRlUXGFCCKs6"
   },
   "outputs": [],
   "source": [
    "# 4. Implement error handling and validation\n",
    "def validate_input(image_paths):\n",
    "    valid_paths = []\n",
    "    for path in image_paths:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Warning: Image file not found: {path}\")\n",
    "        elif not path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"Warning: Unsupported file format: {path}\")\n",
    "        else:\n",
    "            valid_paths.append(path)\n",
    "    return valid_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5h8TfGpCPrC"
   },
   "outputs": [],
   "source": [
    "# 5. Optimize for performance\n",
    "@torch.no_grad()\n",
    "def reconstruct_face(model, image):\n",
    "    model.eval()\n",
    "    vertices, colors = model(image.unsqueeze(0))\n",
    "    return vertices.squeeze(0), colors.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNw-9YnZCTRD",
    "outputId": "f6b2f3bb-41c3-46c3-ee95-dbd57e7a8dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Warning: Image file not found: path/to/image1.jpg\n",
      "Warning: Image file not found: path/to/image2.jpg\n",
      "Warning: Image file not found: path/to/image3.jpg\n",
      "An error occurred: No valid image files provided.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main pipeline\n",
    "def face_reconstruction_pipeline(image_paths, model_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Validate input\n",
    "    valid_image_paths = validate_input(image_paths)\n",
    "    if not valid_image_paths:\n",
    "        raise ValueError(\"No valid image files provided.\")\n",
    "\n",
    "    # Load and preprocess images\n",
    "    dataloader = load_and_preprocess_images(valid_image_paths)\n",
    "\n",
    "    # Load or train the model\n",
    "    num_vertices = 10000  # Adjust based on your needs\n",
    "    model = FaceReconstructionModel(num_vertices).to(device)\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(\"Loaded pre-trained model.\")\n",
    "    else:\n",
    "        print(\"Pre-trained model not found. Training a new model...\")\n",
    "        # Here you would implement the training loop\n",
    "        # For brevity, we'll skip the training implementation\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Model trained and saved.\")\n",
    "\n",
    "    # Reconstruct 3D face\n",
    "    all_vertices = []\n",
    "    all_colors = []\n",
    "    for batch in dataloader:\n",
    "        image = batch.to(device)\n",
    "        try:\n",
    "            vertices, colors = reconstruct_face(model, image)\n",
    "            all_vertices.append(vertices)\n",
    "            all_colors.append(colors)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error during face reconstruction: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if not all_vertices:\n",
    "        raise ValueError(\"Face reconstruction failed for all images.\")\n",
    "\n",
    "    # Average the results if multiple images were provided\n",
    "    final_vertices = torch.stack(all_vertices).mean(dim=0)\n",
    "    final_colors = torch.stack(all_colors).mean(dim=0)\n",
    "\n",
    "    # Create 3D mesh\n",
    "    vertices, faces, colors = create_face_mesh(final_vertices.cpu().numpy(), final_colors.cpu().numpy())\n",
    "\n",
    "    # Render views\n",
    "    renderer = FaceRenderer(device)\n",
    "    rendered_images = renderer.render_views(torch.tensor(vertices, dtype=torch.float32),\n",
    "                                            faces,\n",
    "                                            torch.tensor(colors, dtype=torch.float32))\n",
    "\n",
    "    return vertices, faces, colors, rendered_images\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_paths = [\"path/to/image1.jpg\", \"path/to/image2.jpg\", \"path/to/image3.jpg\"]\n",
    "    model_path = \"path/to/face_reconstruction_model.pth\"\n",
    "\n",
    "    try:\n",
    "        vertices, faces, colors, rendered_images = face_reconstruction_pipeline(image_paths, model_path)\n",
    "\n",
    "        # Save results\n",
    "        save_obj(\"reconstructed_face.obj\",\n",
    "                 torch.tensor(vertices, dtype=torch.float32),\n",
    "                 torch.tensor(faces, dtype=torch.int64),\n",
    "                 verts_uvs=None,\n",
    "                 faces_uvs=None,\n",
    "                 texture_map=torch.tensor(colors, dtype=torch.float32))\n",
    "\n",
    "        for i, img in enumerate(rendered_images):\n",
    "            cv2.imwrite(f\"rendered_view_{i}.png\", cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        print(\"Face reconstruction and rendering complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjUcqKNtCWdP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Class-Pulse",
   "language": "python",
   "name": "class-pulse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
